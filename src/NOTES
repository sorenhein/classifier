Cleaning up clusters
--------------------
Maybe start by getting the periodicity right.  Inputs:
- Periodicity within each cluster.
- For all clusters combined.
- For each cluster, turned into a synthetic, weighted vector.

Intervals (much) longer than the period are removed.
Clusters are recalculated w.r.t. center, length etc., but 
clustering remains.

Look for a cluster with
- The right period
- Many intervals
- lno close to count, >= half
- #per close to lno-1
- no dupes

Clean it of very different lengths -> new cluster.
Check that everything in it is in some periodic relation to
something else in it.



Maybe once we have the period, we start to fix and label things
at this distance.  



There may be some clusters whose lengths track the periodicity.
So lengths AND spacings will be close to multiples.
These should line up neatly in full-length intervals, sometimes
covering multiple lengths, sometimes a single length.
We won't know what the dominant feature is that the lock onto.
We can make a note anyway.
We can also reject spurious intervals out of these clusters that
might be useful elsewhere.

We might have spurious intervals elsewhere as well.





SmallRange doesn't quite work, #23/0, #24, #25, #33/0
#28 asymm ranges pos and neg

2018-09-24
----------
- Need even cleaner peaks before we start clustering.
- s05, 053709, sample 1650: Do we have two peaks? Why not?

2018-09-23
----------
- Detect positive maxima with some streamlining (done)
- Detect negative minima with some streamlining (done)

What's left?

- Positive maxima without a negative minimum in between
  - Can be chatter
  - Can be a proper trough
- Negative minima without a positive maximum in between
  - Can be a negative maximum as a single spike
  - Can be chatter

Combine these into Pieces.

Fill in single spikes and note more complicated behavior.

By now the whole trace should be sliced up.

Look for regularities.

Fill out the complicated pieces.

2018-09-17
----------
- Extract some key periodicity parameters
  - Cluster neighbors (same parameters as single peaks, but two
    together now in the distance measure), hoping to find a strong
    signal for the bogeys.  Might be two clusters or even more.
    - tentatively accepted bogeys
  - For the tentative singles, look for neighbor peaks together with 
    which they would fit a bogey cluster?
    - Look everywhere except in rejected.  Early only if it makes
      quantitative sense (how?)
  - Drop remaining singles except at the beginning and end
  

PeakStats: 
log the category (train or sensor).
Output csv.

Give out the whole PeakList, don't copy into PeakTime?


2018-09-14
----------
We often get the 2nd of maxima above the line.  sensor34, 180956, #2.

Maybe transients can be reduced with filter padding as in filtfilt.


2018-09-02
----------
* Improve the recognition (currently 1072 / 1778 = 60.3%)

* Add separate timers for pre-align and align
* And for peak extraction

* Clean up driver.cpp

2018-07-17
----------
* Some _N and _R trains are almost impossible to separate
  - ICE4_DEU_28 is probably symmetric, in fact?
  - ICE2_DEU_48 ditto?
  - ICE1_old_CHE_56 ditto? [delete?]
  - ICE4_DEU_28 and ICET_DEU_28 have extremely similar ratios

* In doc, make the comments from Train axles.xlsx

* Files to finish:
  SynthTrain cpp and h
  driver.cpp

Visual          OK
mingw           OK
gcc
Mac gcc
Mac clang
Linux

Overall algorithm
-----------------

* Check against laser measurements!
* Output a diagram with the wagons suggested
* throw/catch with error codes (like Build)
* filtfilt padding, how?
* Make independent of sample rate (other than Butterworth?)
* Move to less padding in SegQuiet back
* Implement displacement algorithms
  - Our integration
  - Some kind of scalar product
  - Estimate parameters of the flanks?  What kind of function?
  - Also add timers
* Float (Accel) to double everywhere
* Simpson integration?
